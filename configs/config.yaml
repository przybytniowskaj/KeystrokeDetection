model: "moat"
model_params: default
model_configs:
  coatnet:
    first: #20M
      "image_size": ${image_size}
      "nums_blocks": [2, 2, 3, 2, 2]
      "layer_out_channels": [64, 96, 192, 384, 768]
    second: #78M
      "image_size": ${image_size}
      "nums_blocks": [2, 3, 4, 5, 2]
      "layer_out_channels": [64, 128, 256, 512, 1024]
    third: #68M
      "image_size": ${image_size}
      "nums_blocks": [3, 4, 6, 8, 3]
      "layer_out_channels": [64, 128, 256, 512, 1024]
    fourth: #36M
      "image_size": ${image_size}
      "nums_blocks": [2, 2, 4, 4, 2]
      "layer_out_channels": [64, 96, 192, 384, 768]
    default: #42M
      "image_size": ${image_size}
      "nums_blocks": [2, 2, 3, 5, 2]
      "layer_out_channels": [64, 96, 192, 384, 768]
    bigger: #168M
      "image_size": ${image_size}
      "nums_blocks": [4, 6, 8, 10, 2]
      "layer_out_channels": [64, 192, 384, 512, 1024]
  moat:
    default: #71M
      "img_size": ${image_size}
      "in_channels": 1
      "embed_dim": 128
      "depths": [3,5,9,3]
      "channels": [128, 384, 512, 1024]
      "attn_drop": 0.3
      "drop": 0.3
    default_window: #72M
      "img_size": ${image_size}
      "in_channels": 1
      "embed_dim": 128
      "depths": [3,5,9,3]
      "channels": [128, 384, 512, 1024]
      "attn_drop": 0.3
      "drop": 0.3
      "use_window": true
      "window_size": 16
    smaller: #20M
      "img_size": ${image_size}
      "in_channels": 1
      "embed_dim": 128
      "depths": [2,2,4,2]
      "channels": [128, 256, 396, 512]
      "attn_drop": 0.3
      "drop": 0.3
    smaller_window: #20M
      "img_size": ${image_size}
      "in_channels": 1
      "embed_dim": 128
      "depths": [2,2,4,2]
      "channels": [128, 256, 396, 512]
      "attn_drop": 0.3
      "drop": 0.3
      "use_window": true
      "window_size": 8
    bigger: #116
      "img_size": ${image_size}
      "in_channels": 1
      "embed_dim": 256
      "depths": [3,5,9,3]
      "channels": [256, 512, 768, 1024]
      "attn_drop": 0.3
      "drop": 0.3
    bigger_window: #116M
      "img_size": ${image_size}
      "in_channels": 1
      "embed_dim": 256
      "depths": [3,5,9,3]
      "channels": [256, 512, 768, 1024]
      "attn_drop": 0.3
      "drop": 0.3
      "use_window": true
      "window_size": 16
    bigger2:
      "img_size": ${image_size}
      "in_channels": 1
      "embed_dim": 128
      "depths": [3,5,7,9,3]
      "channels": [128, 256, 512, 768, 1024]
      "attn_drop": 0.3
      "drop": 0.3
  swintransformer:
    default:
      "image_size": ${image_size}
      "patch_size": 4
      "embed_dim": 96
      "depths": [2, 2, 6, 2]
      "num_heads": [3, 6, 12, 24]
      "window_size": 4
      "mlp_ratio": 4.0
      "qkv_bias": true
      "qk_scale": null
      "ape": false
      "patch_norm": true
      "drop_rate": 0.2
      "attn_drop_rate": 0.2
    big: #88M
      "image_size": ${image_size}
      "patch_size": 4
      "embed_dim": 128
      "depths": [2, 4, 18, 2]
      "num_heads": [4, 8, 16, 32]
      "window_size": 8
      "mlp_ratio": 4.0
      "qkv_bias": true
      "qk_scale": null
      "ape": false
      "patch_norm": true
      "drop_rate": 0.2
      "attn_drop_rate": 0.2
    bigger: #156M
      "image_size": ${image_size}
      "patch_size": 4
      "embed_dim": 192
      "depths": [2, 4, 12, 2]
      "num_heads": [4, 8, 16, 24]
      "window_size": 16
      "mlp_ratio": 4.0
      "qkv_bias": true
      "qk_scale": null
      "ape": false
      "patch_norm": true
      "attn_drop_rate": 0.2
      "drop_rate": 0.2

    small:
      "image_size": ${image_size}
      "patch_size": 4
      "embed_dim": 96
      "depths": [2, 3, 2]
      "num_heads": [3, 8, 12]
      "window_size": 4
      "mlp_ratio": 4.0
      "qkv_bias": true
      "qk_scale": null
      "ape": false
      "patch_norm": true
    smaller: #1M
      "image_size": ${image_size}
      "patch_size": 4
      "embed_dim": 48
      "depths": [2, 2, 2]
      "num_heads": [3, 6, 8]
      "window_size": 2
      "mlp_ratio": 4.0
      "qkv_bias": false
      "ape": false
      "patch_norm": true

optimizer: adam
lr: 0.0001
weight_decay: 0
optimizer_configs:
  adam:
    lr: ${lr}
    weight_decay: ${weight_decay}
  sgd:
    lr: ${lr}
    momentum: 0.9
    weight_decay: ${weight_decay}
  rmsprop:
    lr: ${lr}
    alpha: 0.99
    eps: 1e-08
    weight_decay: ${weight_decay}

scheduler: StepLR
scheduler_configs:
  StepLR:
    step_size: 10
    gamma: 0.1
  CosineAnnealingLR:
    T_max: 20
    eta_min: 0.0000001
  OneCycleLR:
    total_steps: ${num_epochs}
    anneal_strategy: "cos"
    max_lr: 0.001
  CosineAnnealingWarmRestarts:
    T_0: 10
    T_mult: 2
    eta_min: 0.0000001
  ReduceLROnPlateau:
    mode: "min"
    factor: 0.1
    patience: 5
    threshold: 0.0001
    threshold_mode: "rel"
    cooldown: 0
    min_lr: 0.000001
    eps: 1e-08


num_epochs: 1500
batch_size: 512
num_workers: 1
max_no_improvement: 50
transform_aug: true
transform: false
seed: 42
interim_results: "/mnt/evafs/groups/zychowski-lab/jprzybytniowska/KeystrokeDetection/interim_results/"
project_name: "master-thesis"
special_keys: false
partial_wd: false
exclude_few_special_keys: true
image_size: 64
class_encoding: ''
init_linear: true
